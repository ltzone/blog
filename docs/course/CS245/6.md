---
title: 
date: 2021-03-29 08:42:17
tags: 
- Data Science

categories: 
- Courses

sidebar: true
lang: en-US
---

How to measure the distance?

<!-- more -->


## Distance between Samples

### Minkowski(Lp) Distance

<!-- TODO -->

- $p=\infty$, Chebyshev distance $d(x,y) = \max_i |x_i - y_i|$
- $p=2$, Euclidean distance $d(x,y) = \sqrt{\sum_i |x_i - y_i|^2}$
- $p=1$, Manhattan distance $d(x,y) = \sum_i |x_i - y_i|$

### Cosine Distance



::: tip

- Similarity / Affinity / Proximity
- Dissimilarity / Distance

:::

### What if two samples are hetrogeneous

- Hetrogeneous Features
  - normalization
- Hetrogeneous Modularities
  - e.g. visual feature + texture feature
  - application. cross-modularity information retrieval

#### Metric Learning

Project $\mathbf{x}$ and $\mathbf{y}$ to a common space $d(\mathbf{x},\mathbf{y})\Leftarrow d(\mathbf{Px},\mathbf{Py})$ 

Mahalanobis distance: extension of Euclidean distance

$d(\mathbf{Px},\mathbf{Py}) = ||\mathbf{Px} - \mathbf{Py} || = \sqrt{(x^T-y^T)P^TP(x-y)} = \sqrt{(x^T-y^T)M(x-y)}$

> We can learn $M$ directly instead of the projection $P$



Goal of learning $M$:

> Max the distance between clusters, while maintaining distance within cluster small $\le 1$ or $\le C$ learnable
> $\mathbf{M}$ should be semi-definite because it is $P^TP$

<!-- TODO -->

> Research going on in optimizaiton this problem


### Earth Mover's Distance (EMD) 推土距离

> The distance between two clusters of data $\mathcal{S}$, $\mathcal{T}$, every datapoint $x_i^{s/t}$ has a weight $w_i^{s/t}$
> 
> The distance between $x$s can be calculated

e.g. How to compute the distance between Image A and Image B based on color histogram

> every $x$ corresponds to a range of colors, $w$ corresponds to its histogram height (pixel counts)

> Minimize the work(功) it requries to move earth from source to distance







## Distance between Distributions

